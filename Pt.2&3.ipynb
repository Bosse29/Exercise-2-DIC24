{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85af0eae-59d8-49f2-972f-c26abd2fc1a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise 2 - Text Processing and Classification using Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8510e59a-1556-4dd9-842e-cbcc464f315b",
   "metadata": {},
   "source": [
    "## Part 2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fab9eba1-9e07-4266-84d8-6da799b4185c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, IDF, ChiSqSelector,  StringIndexer, Normalizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "import json \n",
    "from operator import add\n",
    "import re\n",
    "from heapq import nlargest\n",
    "\n",
    "from pyspark.ml.classification import LinearSVC,  OneVsRest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "db078ad9-d9c1-4ec5-afc3-8fc40f82eec2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "SLF4J: Class path contains multiple SLF4J bindings.\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/spark/jars/slf4j-log4j12-1.7.30.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: Found binding in [jar:file:/usr/lib/hadoop/lib/slf4j-reload4j-1.7.36.jar!/org/slf4j/impl/StaticLoggerBinder.class]\n",
      "SLF4J: See http://www.slf4j.org/codes.html#multiple_bindings for an explanation.\n",
      "SLF4J: Actual binding is of type [org.slf4j.impl.Log4jLoggerFactory]\n",
      "24/05/29 16:31:37 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "24/05/29 16:31:41 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "#starting spark session\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4c468a8d-20b5-448d-bc75-0cecba907e63",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "#we are using the review_devset from the cluster. After that we keep only the necessary columns\n",
    "\n",
    "textDF = spark.read.json(\"hdfs:///user/dic24_shared/amazon-reviews/full/reviews_devset.json\").createOrReplaceTempView(\"review\")\n",
    "df = spark.sql(\"SELECT category,reviewText FROM review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "02048538-14c8-4767-8b24-c294f3ff4307",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+--------------------+\n",
      "|            category|          reviewText|\n",
      "+--------------------+--------------------+\n",
      "|Patio_Lawn_and_Garde|This was a gift f...|\n",
      "|Patio_Lawn_and_Garde|This is a very ni...|\n",
      "|Patio_Lawn_and_Garde|The metal base wi...|\n",
      "|Patio_Lawn_and_Garde|For the most part...|\n",
      "|Patio_Lawn_and_Garde|This hose is supp...|\n",
      "|Patio_Lawn_and_Garde|This tool works v...|\n",
      "|Patio_Lawn_and_Garde|This product is a...|\n",
      "|Patio_Lawn_and_Garde|I was excited to ...|\n",
      "|Patio_Lawn_and_Garde|I purchased the L...|\n",
      "|Patio_Lawn_and_Garde|Never used a manu...|\n",
      "|Patio_Lawn_and_Garde|Good price. Good ...|\n",
      "|Patio_Lawn_and_Garde|I have owned the ...|\n",
      "|Patio_Lawn_and_Garde|I had \"won\" a sim...|\n",
      "|Patio_Lawn_and_Garde|The birds ate all...|\n",
      "|Patio_Lawn_and_Garde|Bought last summe...|\n",
      "|Patio_Lawn_and_Garde|I knew I had a mo...|\n",
      "|Patio_Lawn_and_Garde|I was a little wo...|\n",
      "|Patio_Lawn_and_Garde|I have used this ...|\n",
      "|Patio_Lawn_and_Garde|I actually do not...|\n",
      "|Patio_Lawn_and_Garde|Just what I  expe...|\n",
      "+--------------------+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d8a40dd-5665-427c-9a72-63393d2ce2dc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "stopwordsPath = \"DIC2/stopwords.txt\"\n",
    "stopwords = spark.sparkContext.textFile(stopwordsPath).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "aeb04b50-9310-4c62-afea-b538d4a9820f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "tokenizer = RegexTokenizer(inputCol=\"reviewText\", outputCol=\"words\", pattern=\"\\\\s+|\\\\d+|[()\\\\[\\\\]{}.,;!?:+=\\\\-_\\\"'`~#@&*%€$§\\\\/]+\", toLowercase=True)\n",
    "remover = StopWordsRemover(inputCol=\"words\", outputCol=\"filtered\", caseSensitive=False)\n",
    "vectorizer = CountVectorizer(inputCol=\"filtered\", outputCol=\"vectorized\")\n",
    "idf = IDF(inputCol=\"vectorized\", outputCol=\"tfidf\")\n",
    "encoder = StringIndexer(inputCol=\"category\", outputCol=\"label\")\n",
    "chi2000 = ChiSqSelector(featuresCol=\"tfidf\", labelCol=\"label\", outputCol=\"selected\", numTopFeatures=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "14076980-fda6-48ec-9aeb-f1e398cc645a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "pipeline = Pipeline().setStages([tokenizer, remover, vectorizer, idf, encoder, chi2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4cee33b3-5551-4458-a586-e406a9c4c332",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/29 16:32:31 WARN DAGScheduler: Broadcasting large task binary with size 1060.2 KiB\n",
      "24/05/29 16:32:44 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/05/29 16:32:44 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "24/05/29 16:32:55 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n",
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "pipelineModel = pipeline.fit(df)\n",
    "transformedData = pipelineModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "68b8252d-112c-4922-a44a-b1f9fece4800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "selectedFeatures = pipelineModel.stages[5].selectedFeatures\n",
    "words = pipelineModel.stages[2].vocabulary\n",
    "\n",
    "output = set()\n",
    "for i in selectedFeatures:\n",
    "    output.add(words[i])\n",
    "\n",
    "sorted_output = sorted(list(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d119a19f-bf87-475d-8adb-7921d3dee60e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with open('output_ds.txt', 'w') as f:  \n",
    "    f.write(str(re.sub(\",|'|[0-9]|\\[|\\]|\\.\",\"\", str(sorted_output))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580f9e46-a82a-4c1d-934d-0760ce290872",
   "metadata": {},
   "source": [
    "## Part 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7a912dae-d372-4fbe-994b-5a7f32bc2ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=transformedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8be713b1-6e55-4a40-9852-28aee9f6eec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#downsampling because the dataframe is too big and we're getting too much warning about it. Also the training is superlong. To use the whole dataframe simply delete this cell\n",
    "\n",
    "df=df.sample(fraction=0.1, seed=4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "5f429bb8-c806-4207-86ac-44c0ae62b957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df2=df.select(\"label\", \"selected\").toDF(\"label\", \"selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "84a846ba-dd2f-4ced-b6df-de361ef26cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "normalizer = Normalizer().setInputCol(\"selected\").setOutputCol(\"normalized\").setP(2.0)\n",
    "df_norm =normalizer.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98741123-29a7-45a2-9542-df0a95d785fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df3=df_norm.select(\"label\", \"normalized\").toDF(\"label\", \"normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4a506066-ed6f-4453-be96-78dc8d98a8fd",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/29 16:33:51 WARN DAGScheduler: Broadcasting large task binary with size 2.5 MiB\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+--------------------+\n",
      "|label|          normalized|\n",
      "+-----+--------------------+\n",
      "| 18.0|(2000,[5,7,8,9,27...|\n",
      "| 18.0|(2000,[2,25,45,17...|\n",
      "| 18.0|(2000,[1,4,9,15,1...|\n",
      "| 18.0|(2000,[3,4,8,24,2...|\n",
      "| 18.0|(2000,[4,558,1265...|\n",
      "| 18.0|(2000,[74,265,288...|\n",
      "| 18.0|(2000,[11,28,49,3...|\n",
      "| 18.0|(2000,[0,2,5,18,8...|\n",
      "| 18.0|(2000,[1,3,26,57,...|\n",
      "| 18.0|(2000,[10,49,202,...|\n",
      "| 18.0|(2000,[1,2,6,16,3...|\n",
      "| 18.0|(2000,[1,2,15,25,...|\n",
      "| 18.0|(2000,[1,31,38,39...|\n",
      "| 18.0|(2000,[1,3,4,20,3...|\n",
      "| 18.0|(2000,[1,8,9,14,1...|\n",
      "| 18.0|(2000,[3,49,77,16...|\n",
      "| 18.0|(2000,[13,185,630...|\n",
      "| 18.0|(2000,[14,80,166,...|\n",
      "| 18.0|(2000,[9,43,49,50...|\n",
      "| 18.0|(2000,[3,4,7,26,3...|\n",
      "+-----+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "389f3716-2679-432d-975c-22b84999ae41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#splitting and making it reproducible\n",
    "train,val, test = df3.randomSplit([0.8,0.1, 0.1], seed = 4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663cd330-2f1b-4898-91b0-e14831ebbcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvc = LinearSVC(featuresCol=\"normalized\", labelCol=\"label\", maxIter=10)\n",
    "ovr = OneVsRest(classifier=lsvc, featuresCol=\"normalized\", labelCol=\"label\")\n",
    "ovr_model = ovr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "384c700c-e65a-408e-9461-79ad51defe9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "grid= ParamGridBuilder().addGrid(lsvc.regParam, [0.001, 0.01, 0.1] ).addGrid(lsvc.standardization, [True, False] ).addGrid(lsvc.maxIter, [10, 8]).build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "716082cc-fcf2-467a-a4aa-d8ccba23e69f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "evaluator=MulticlassClassificationEvaluator(metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "5d9236c9-4727-4da0-931f-e6cef0cc7763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "cv=CrossValidator(estimator=lsvc, estimatorParamMaps=grid, evaluator=evaluator, numFolds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fcb672-46ec-41f2-91ee-126ad3ea7eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_model=cv.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085036df-a803-47d2-a0ff-fb417a098c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model=cv_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9896629-629d-43bd-82d8-c0a8faabc5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions_test=best_model.transform(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2845250-9d31-4616-bfd9-dab1e7bae862",
   "metadata": {},
   "outputs": [],
   "source": [
    "ovr_predictions_test = ovr_model.transform(test)\n",
    "ovr_f1_score = evaluator.evaluate(ovr_predictions_test)\n",
    "print(f\"OVR F1 Score: {ovr_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f4e0fd-83db-4619-9c2d-4b603fa2af7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model_predictions_test = best_model.transform(test)\n",
    "best_model_f1_score = evaluator.evaluate(best_model_predictions_test)\n",
    "print(f\"Best Model F1 Score: {best_model_f1_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (DIC24)",
   "language": "python",
   "name": "python3_dic24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
