{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85af0eae-59d8-49f2-972f-c26abd2fc1a2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Exercise 2 - Text Processing and Classification using Spark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8510e59a-1556-4dd9-842e-cbcc464f315b",
   "metadata": {},
   "source": [
    "## Part 2 \n",
    "\n",
    "Convert the review texts to a classic vector space representation with TFIDF-weighted features based on the Spark DataFrame/Dataset API by building a transformation pipeline. The primary goal of this part is the preparation of the pipeline for Part 3 (see below). Note: although parts of this pipeline will be very similar to Assignment 1 or Part 1 above, do not expect to obtain identical results or have access to all intermediate outputs to compare the individual steps.\n",
    "\n",
    "Use built-in functions for tokenization to unigrams at **whitespaces, tabs, digits, and the delimiter characters, casefolding, stopword removal, TF-IDF calculation, and chi square selection** (using 2000 top terms overall). Write the terms selected this way to a file **output_ds.txt** and compare them with the terms selected in Assignment 1. Describe your observations briefly in the submission report (see Part 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fab9eba1-9e07-4266-84d8-6da799b4185c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#importing libraries\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.ml.feature import RegexTokenizer, StopWordsRemover, CountVectorizer, IDF, ChiSqSelector,  StringIndexer, Normalizer\n",
    "from pyspark.ml import Pipeline\n",
    "from pyspark.ml.tuning import ParamGridBuilder, CrossValidator\n",
    "from pyspark.ml.evaluation import MulticlassClassificationEvaluator\n",
    "\n",
    "from pyspark.ml.stat import ChiSquareTest\n",
    "from pyspark import SparkContext\n",
    "from pyspark import SparkConf\n",
    "import json \n",
    "from operator import add\n",
    "import re\n",
    "from heapq import nlargest\n",
    "\n",
    "from pyspark.ml.classification import LinearSVC,  OneVsRest\n",
    "from pyspark.ml.regression import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db078ad9-d9c1-4ec5-afc3-8fc40f82eec2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "24/05/29 20:58:52 WARN SparkContext: Another SparkContext is being constructed (or threw an exception in its constructor). This may indicate an error, since only one SparkContext should be running in this JVM (see SPARK-2243). The other SparkContext was created at:\n",
      "org.apache.spark.api.java.JavaSparkContext.<init>(JavaSparkContext.scala:58)\n",
      "sun.reflect.NativeConstructorAccessorImpl.newInstance0(Native Method)\n",
      "sun.reflect.NativeConstructorAccessorImpl.newInstance(NativeConstructorAccessorImpl.java:62)\n",
      "sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)\n",
      "java.lang.reflect.Constructor.newInstance(Constructor.java:423)\n",
      "py4j.reflection.MethodInvoker.invoke(MethodInvoker.java:247)\n",
      "py4j.reflection.ReflectionEngine.invoke(ReflectionEngine.java:357)\n",
      "py4j.Gateway.invoke(Gateway.java:238)\n",
      "py4j.commands.ConstructorCommand.invokeConstructor(ConstructorCommand.java:80)\n",
      "py4j.commands.ConstructorCommand.execute(ConstructorCommand.java:69)\n",
      "py4j.ClientServerConnection.waitForCommands(ClientServerConnection.java:182)\n",
      "py4j.ClientServerConnection.run(ClientServerConnection.java:106)\n",
      "java.lang.Thread.run(Thread.java:750)\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4042. Attempting port 4043.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4043. Attempting port 4044.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4044. Attempting port 4045.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4045. Attempting port 4046.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4046. Attempting port 4047.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4047. Attempting port 4048.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4048. Attempting port 4049.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4049. Attempting port 4050.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4050. Attempting port 4051.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4051. Attempting port 4052.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4052. Attempting port 4053.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4053. Attempting port 4054.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4054. Attempting port 4055.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4055. Attempting port 4056.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4056. Attempting port 4057.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4057. Attempting port 4058.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4058. Attempting port 4059.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4059. Attempting port 4060.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4060. Attempting port 4061.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4061. Attempting port 4062.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4062. Attempting port 4063.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4063. Attempting port 4064.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4064. Attempting port 4065.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4065. Attempting port 4066.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4066. Attempting port 4067.\n",
      "24/05/29 20:58:53 WARN Utils: Service 'SparkUI' could not bind on port 4067. Attempting port 4068.\n",
      "24/05/29 20:58:53 WARN Client: Neither spark.yarn.jars nor spark.yarn.archive is set, falling back to uploading libraries under SPARK_HOME.\n"
     ]
    }
   ],
   "source": [
    "#starting spark session\n",
    "\n",
    "spark = SparkSession.builder.getOrCreate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c468a8d-20b5-448d-bc75-0cecba907e63",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#we are using the review_devset from the cluster. After that we keep only the necessary columns\n",
    "# load the data from hadoop and making temprary view\n",
    "# selecting category and reviewText from this view\n",
    "\n",
    "textDF = spark.read.json(\"hdfs:///user/dic24_shared/amazon-reviews/full/reviews_devset.json\").createOrReplaceTempView(\"review\")\n",
    "df = spark.sql(\"SELECT category,reviewText FROM review\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02048538-14c8-4767-8b24-c294f3ff4307",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d8a40dd-5665-427c-9a72-63393d2ce2dc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#we have uploaded the stopword.txt to our cluster. Here, we're using that.\n",
    "\n",
    "stopwordsPath = \"Exercise2/stopwords.txt\"\n",
    "# reading the contents of the stopwords file into an RDD and with collect collecting all the elements of it and returning as a list\n",
    "stopwords = spark.sparkContext.textFile(stopwordsPath).collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb04b50-9310-4c62-afea-b538d4a9820f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#assembling the pipeline. \n",
    "# we use regextokenizer to tokenize and low case the words\n",
    "# we use StopWordsRemover to remove the stopwords\n",
    "# we use CounteVectorizer to Vectorize and Count them\n",
    "# we use Inverse Document Frequency, a component of the TF-IDF scoring mechanism\n",
    "# we convert categorical strings in the \"category\" column into numerical labels in the \"label\" column\n",
    "# we use ChiSqSelector to Selects the top 2000 features from the \"tfidf\" column that are most relevant to the \"label\" column, and stores them in the \"selected\" column\n",
    "\n",
    "tokenizer = RegexTokenizer(inputCol=\"reviewText\", outputCol=\"words\", pattern=\"\\\\s+|\\\\d+|[()\\\\[\\\\]{}.,;!?:+=\\\\-_\\\"'`~#@&*%€$§\\\\/]+\", toLowercase=True)\n",
    "remover = StopWordsRemover(inputCol=\"words\", stopWords=stopwords,outputCol=\"filtered\", caseSensitive=False)\n",
    "vectorizer = CountVectorizer(inputCol=\"filtered\", outputCol=\"vectorized\")\n",
    "idf = IDF(inputCol=\"vectorized\", outputCol=\"tfidf\")\n",
    "encoder = StringIndexer(inputCol=\"category\", outputCol=\"label\")\n",
    "chi2000 = ChiSqSelector(featuresCol=\"tfidf\", labelCol=\"label\", outputCol=\"selected\", numTopFeatures=2000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14076980-fda6-48ec-9aeb-f1e398cc645a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# we create a pipeline that sequentially applies the series of transformations and feature selection steps that we created \n",
    "\n",
    "pipeline = Pipeline().setStages([tokenizer, remover, vectorizer, idf, encoder, chi2000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cee33b3-5551-4458-a586-e406a9c4c332",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# fits the pipeline to the df\n",
    "pipelineModel = pipeline.fit(df)\n",
    "# transforms the original df using the learned transformations\n",
    "transformedData = pipelineModel.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68b8252d-112c-4922-a44a-b1f9fece4800",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Select the selected features from the ChiSqSelector\n",
    "selectedFeatures = pipelineModel.stages[5].selectedFeatures\n",
    "# Select the list of words that the vectorizer has indexed and used to create the term frequency vectors\n",
    "words = pipelineModel.stages[2].vocabulary\n",
    "\n",
    "# find the respective words and add them to output\n",
    "output = set()\n",
    "for i in selectedFeatures:\n",
    "    output.add(words[i])\n",
    "\n",
    "#Sorted list of words corresponding to the selected features\n",
    "sorted_output = sorted(list(output))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3774715a-f48d-4ace-a50d-c8c367ab9e8a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sorted_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d119a19f-bf87-475d-8adb-7921d3dee60e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Save the ouput\n",
    "with open('output_ds.txt', 'w') as f:  \n",
    "    f.write(str(re.sub(\",|'|[0-9]|\\[|\\]|\\.\",\"\", str(sorted_output))))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580f9e46-a82a-4c1d-934d-0760ce290872",
   "metadata": {},
   "source": [
    "## Part 3\n",
    "\n",
    "In this part, you will train a text classifier from the features extracted in Part 2. The goal is to learn a model that can predict the product category from a review's text.\n",
    "\n",
    "To this end, extend the pipeline from Part 2 such that a Support Vector Machine classifier is trained. Since we are dealing with multi-class problems, make sure to put a strategy in place that allows binary classifiers to be applicable. Apply vector length normalization before feeding the feature vectors into the classifier (use Normalizer with L2 norm).\n",
    "\n",
    "Follow best practices for machine learning experiment design and investigate the effects of parameter settings using the functions provided by Spark:\n",
    "\n",
    "- Split the review data into training, validation, and test set.\n",
    "\n",
    "- Make experiments reproducible.\n",
    "\n",
    "- Use a grid search for parameter optimization:\n",
    "\n",
    "    - Compare chi square overall top 2000 filtered features with another, heavier filtering with much less dimensionality (see Spark ML documentation for options).\n",
    "\n",
    "    - Compare different SVM settings by varying the regularization parameter (choose 3 different values), standardization of training features (2 values), and maximum number of iterations (2 values).\n",
    "\n",
    "- Use the MulticlassClassificationEvaluator to estimate performance of your trained classifiers on the test set, using F1 measure as criterion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a912dae-d372-4fbe-994b-5a7f32bc2ae1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df=transformedData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8be713b1-6e55-4a40-9852-28aee9f6eec6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#downsampling because the dataframe is too big and we're getting too much warning about it\n",
    "# Also the training is superlong\n",
    "# To use the whole dataframe simply delete this cell\n",
    "\n",
    "df=df.sample(fraction=0.01, seed=4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f429bb8-c806-4207-86ac-44c0ae62b957",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Selecting label and selected columns from df\n",
    "df2=df.select(\"label\", \"selected\").toDF(\"label\", \"selected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84a846ba-dd2f-4ced-b6df-de361ef26cf0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#as asked in the task we normalize the \"selected\" column with L2\n",
    "# Sets the normalization parameter to 2.0, which corresponds to L2 normalization\n",
    "\n",
    "normalizer = Normalizer().setInputCol(\"selected\").setOutputCol(\"normalized\").setP(2.0)\n",
    "df_norm =normalizer.transform(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98741123-29a7-45a2-9542-df0a95d785fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#deleting unnecessary columns\n",
    "\n",
    "df3=df_norm.select(\"label\", \"normalized\").toDF(\"label\", \"normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a506066-ed6f-4453-be96-78dc8d98a8fd",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df3.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "389f3716-2679-432d-975c-22b84999ae41",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#splitting the data and making it reproducible\n",
    "# splitting it randomly:\n",
    "# train: Contains 70% of the data\n",
    "# val: Contains 15% of the data\n",
    "# test: Contains another 15% of the data\n",
    "\n",
    "train,val, test = df3.randomSplit([0.7,0.15, 0.15], seed = 4242)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "663cd330-2f1b-4898-91b0-e14831ebbcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializes a Linear Support Vector Classifier (LinearSVC) for binary classification and then \n",
    "# Sets up the One-vs-Rest (OvR) strategy for multi-class classification\n",
    "# Fits the OvR model to the training data\n",
    "lsvc = LinearSVC(featuresCol=\"normalized\", labelCol=\"label\", maxIter=10)\n",
    "ovr = OneVsRest(classifier=lsvc, featuresCol=\"normalized\", labelCol=\"label\")\n",
    "ovr_model = ovr.fit(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "384c700c-e65a-408e-9461-79ad51defe9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#setting up the parameter grid for gridsearch. We tried to keep the iteration count low, as it's already too slow.\n",
    "#We need nested parameters because we also nested the classifiers\n",
    "# This dictionary is containing hyperparameters\n",
    "# classifier__regParam: This parameter controls the regularization strength of the classifier\n",
    "# classifier__standardization: This parameter determines whether or not to standardize the features before training the model\n",
    "# classifier__maxIter: This parameter controls the maximum number of iterations for optimization algorithms.\n",
    "param_grid_dict = {\n",
    "    \"classifier__regParam\": [0.001, 0.01, 0.1],\n",
    "    \"classifier__standardization\": [True, False],\n",
    "    \"classifier__maxIter\": [10, 8]\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26989cd4-83a9-474d-b9e1-bfa89fb02e84",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ParamGridBuilder(): Initializes a builder for parameter grids\n",
    "param_grid_builder = ParamGridBuilder()\n",
    "# iterates over each hyperparameter and its corresponding values in the dictionary\n",
    "# getattr(lsvc, param.split(\"__\")[1]) select the attribute of the LinearSVC based on the parameter name\n",
    "# It dynamically accesses the attribute corresponding to the parameter name by splitting the parameter name using __ selecting the second part\n",
    "# Values are the hyperparameter values specified in param_grid_dict for the current parameter\n",
    "for param, values in param_grid_dict.items():   \n",
    "    param_grid_builder = param_grid_builder.addGrid(getattr(lsvc, param.split(\"__\")[1]), values)\n",
    "\n",
    "# Building the parameter grid using the added grids\n",
    "param_grid = param_grid_builder.build()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "716082cc-fcf2-467a-a4aa-d8ccba23e69f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#For evaluation we use the recommended MulticlassClassificationEvaluator\n",
    "# MulticlassClassificationEvaluator is an evaluator used to evaluate multiclass classification models\n",
    "# The F1 score is the harmonic mean of precision and recall\n",
    "evaluator=MulticlassClassificationEvaluator(metricName=\"f1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d9236c9-4727-4da0-931f-e6cef0cc7763",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Here we initalize the crossvalidator\n",
    "# numFolds: The number of folds in cross-validation (2-fold cross-validation)\n",
    "cv=CrossValidator(estimator=ovr, estimatorParamMaps=param_grid, evaluator=evaluator, numFolds=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94772ec6-155c-4777-a303-3cea12112030",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val.groupBy(\"label\").count().show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4fcb672-46ec-41f2-91ee-126ad3ea7eb4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#For a \"quick\" run we use the validation dataset to find the best model using the crossvalidator\n",
    "\n",
    "cv_model=cv.fit(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "085036df-a803-47d2-a0ff-fb417a098c81",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting our best model to compare to our original one\n",
    "best_model=cv_model.bestModel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2845250-9d31-4616-bfd9-dab1e7bae862",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculating the original model's f1 score. Using the test data\n",
    "\n",
    "ovr_predictions_test = ovr_model.transform(test)\n",
    "ovr_f1_score = evaluator.evaluate(ovr_predictions_test)\n",
    "print(f\"OVR F1 Score: {ovr_f1_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f4e0fd-83db-4619-9c2d-4b603fa2af7b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#calculating the best model's f1 score. we're using the test data\n",
    "best_model_predictions_test = best_model.transform(test)\n",
    "best_model_f1_score = evaluator.evaluate(best_model_predictions_test)\n",
    "print(f\"Best Model F1 Score: {best_model_f1_score}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (DIC24)",
   "language": "python",
   "name": "python3_dic24"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
